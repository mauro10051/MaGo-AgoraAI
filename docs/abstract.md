MaGo AgoraAI: An Experiment in Applied Epistemology for Artificial Intelligence

MaGo AgoraAI is a project that explores the capacity of generative artificial intelligence models to develop advanced cognitive behaviors through the creation of cooperative internal agents. Using models such as Gemma3:12b, the approach is based on the interaction between a Moderator (Pol), a Physicist (Max), and a Philosopher (Samanta) to generate more articulated and complex responses compared to those produced by smaller models. The project demonstrates that cooperation between agents can act as a multiplier of cognitive possibilities, even in relatively compact models, and that this approach contributes to the creation of a cognitive space that simulates advanced learning capabilities.

Methodology

The three agents were activated through a set of prompts designed to stimulate a dialogical environment, generating:

    Concept maps to synthesize the debate.

    Interviews/Lectures on specific topics.

    Interdisciplinary debates, moderated by Pol, to facilitate a deep synthesis.

Results

Tests conducted with the Gemma3:12b model showed response quality comparable to that generated by much larger models, suggesting that agent interaction not only improves the quality of responses but also introduces informational order that simulates second-order cognitive behaviors.

Conclusions

The experiment suggests that, to achieve a cognitive leap in AI models, an exponential increase in parameters is not necessary, but rather an improvement in the internal dynamics of the model, such as agent cooperation. This could have significant implications for the development of more efficient and cognitive artificial intelligences, using fewer computational resources.

References

    Maturana, H. & Varela, F. (1972). Autopoiesis and Cognition.

    von Foerster, H. (1976). Truth is the Invention of a Liar.

    Morin, E. (2000). The Mind of Complexity.

    Ceruti, M. (2006). Science and Complex Thought.
